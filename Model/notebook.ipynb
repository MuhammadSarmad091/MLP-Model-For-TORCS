{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "data_dir = \"./\"\n",
    "RAW_CSV = f\"{data_dir}Dataset.csv\"\n",
    "SCALER_PATH = f\"{data_dir}scaler_input.pkl\"\n",
    "\n",
    "# 1) Load raw TORCS log data\n",
    "print(\"Loading raw data from:\", RAW_CSV)\n",
    "df = pd.read_csv(RAW_CSV)\n",
    "\n",
    "# 2) Drop countdown / pre-start rows (curLapTime < 0)\n",
    "df = df[df[\"CurrentLapTime\"] >= 0].reset_index(drop=True)\n",
    "print(\"Dropped pre-start rows; remaining rows:\", df.shape[0])\n",
    "\n",
    "# 3) Drop unused / meta columns (keep 'gear' as feature)\n",
    "drop_cols = [\n",
    "    \"Damage\", \"CurrentLapTime\", \"DistanceFromStart\",\n",
    "    \"DistanceCovered\", \"FuelLevel\", \"LastLapTime\",\n",
    "    \"RacePosition\"\n",
    "]\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "# 4) Define feature & label columns, include 'gear' as feature\n",
    "track_cols = [f\"Track_{i}\" for i in range(1,20)]\n",
    "wsv_cols   = [f\"WheelSpinVelocity_{i}\" for i in range(1,5)]\n",
    "opp_cols   = [f\"Opponent_{i}\" for i in range(1,37)]\n",
    "\n",
    "feature_cols = [\"Angle\"] + opp_cols + [\n",
    "    \"RPM\", \"SpeedX\", \"SpeedY\", \"SpeedZ\", \"TrackPosition\", \"Z\", \"gear\"\n",
    "] + track_cols + wsv_cols\n",
    "label_cols   = [\"Clutch\", \"Braking\", \"Steering\", \"Acceleration\", \"Gear\"]  # gear removed from label\n",
    "\n",
    "# 5) Normalize features into [0,1] using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_norm = scaler.fit_transform(df[feature_cols])\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "print(\"Fitted MinMaxScaler including gear and saved scaler.\")\n",
    "\n",
    "# 6) Prepare labels (gear is now input, so labels exclude it)\n",
    "y_df = df[label_cols].reset_index(drop=True)\n",
    "\n",
    "# 7) Convert normalized features back to DataFrame\n",
    "X_norm_df = pd.DataFrame(X_norm, columns=feature_cols)\n",
    "\n",
    "# 8) Train/validation split and save\n",
    "test_size = 0.2\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_norm_df, y_df,\n",
    "    test_size=test_size,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "X_train.to_csv(f\"{data_dir}train_X.csv\", index=False)\n",
    "X_val.to_csv(f\"{data_dir}val_X.csv\", index=False)\n",
    "y_train.to_csv(f\"{data_dir}train_y.csv\", index=False)\n",
    "y_val.to_csv(f\"{data_dir}val_y.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing complete:\")\n",
    "print(\" train_X shape:\", X_train.shape)\n",
    "print(\" val_X shape:  \", X_val.shape)\n",
    "print(\" train_y shape:\", y_train.shape)\n",
    "print(\" val_y shape:  \", y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fdcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Paths\n",
    "data_dir = \"./\"\n",
    "TRAIN_X = f\"{data_dir}train_X.csv\"\n",
    "TRAIN_Y = f\"{data_dir}train_y.csv\"\n",
    "VAL_X   = f\"{data_dir}val_X.csv\"\n",
    "VAL_Y   = f\"{data_dir}val_y.csv\"\n",
    "MODEL_PATH = f\"{data_dir}trained_model.h5\"\n",
    "\n",
    "# 1) Load preprocessed training and validation data\n",
    "X_train = pd.read_csv(TRAIN_X).values\n",
    "y_train = pd.read_csv(TRAIN_Y).values\n",
    "X_val   = pd.read_csv(VAL_X).values\n",
    "y_val   = pd.read_csv(VAL_Y).values\n",
    "\n",
    "# 2) Build a feed-forward neural network with added layers\n",
    "model = Sequential([\n",
    "    Dense(1024, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(y_train.shape[1])\n",
    "])\n",
    "\n",
    "# 3) Compile model with learning rate 1e-4\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# 4) Set up callbacks including LR reduction on plateau\n",
    "callbacks = [\n",
    "    ModelCheckpoint(MODEL_PATH, save_best_only=True, monitor='val_loss'),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "# 5) Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 6) Save final model\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"Model training complete. Best model saved to {MODEL_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
